{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOAtjgy9tHW3G+0goWiGLIh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KTFplus/KTFfintune/blob/master/smallwthdrivedata.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q torch transformers datasets librosa evaluate jiwer peft soundfile"
      ],
      "metadata": {
        "id": "QGkVEFg5-HGH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xft0bzQr-Db7"
      },
      "outputs": [],
      "source": [
        "# @title ğŸ¤– Whisper íŒŒì¸íŠœë‹ì„ ìœ„í•œ Colab ìµœì í™” ì½”ë“œ (RAM ìµœì í™” ë²„ì „)\n",
        "# @markdown ## 1. í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜ (í•„ìš”í•œ ê²½ìš° ì‹¤í–‰)\n",
        "# !pip install -q transformers datasets librosa evaluate jiwer peft soundfile\n",
        "\n",
        "# @markdown ## 2. Google Drive ë§ˆìš´íŠ¸\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# @markdown ## 3. ê²½ë¡œ ë° ê¸°ë³¸ ì„¤ì •\n",
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gc\n",
        "import logging\n",
        "from tqdm.auto import tqdm\n",
        "from datasets import Dataset, Audio, load_from_disk\n",
        "from transformers import (\n",
        "    WhisperProcessor,\n",
        "    WhisperForConditionalGeneration,\n",
        "    Seq2SeqTrainer,\n",
        "    Seq2SeqTrainingArguments,\n",
        "    DataCollatorForSeq2Seq\n",
        ")\n",
        "from peft import LoraConfig, get_peft_model\n",
        "import evaluate\n",
        "\n",
        "# PyTorch ë©”ëª¨ë¦¬ ë‹¨í¸í™” ë°©ì§€ ì„¤ì •\n",
        "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:128'\n",
        "\n",
        "# ë¡œê¹… ì„¤ì •\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# ë°ì´í„°ì…‹ ê²½ë¡œ (Google Drive ë‚´ ìœ„ì¹˜)\n",
        "dataset_path = \"/content/drive/MyDrive/train_B_Normalized\"  # @param {type:\"string\"}\n",
        "output_dir = \"/content/drive/MyDrive/whisper_finetuned\"  # @param {type:\"string\"}\n",
        "preprocessed_dir = \"/content/drive/MyDrive/preprocessed_whisper\"  # @param {type:\"string\"}\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "os.makedirs(preprocessed_dir, exist_ok=True)\n",
        "\n",
        "# ë©”ëª¨ë¦¬ ì •ë¦¬ í•¨ìˆ˜ - ë” ì² ì €í•˜ê²Œ\n",
        "def clear_memory():\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "    import psutil\n",
        "    process = psutil.Process(os.getpid())\n",
        "    logger.info(f\"ë©”ëª¨ë¦¬ ì •ë¦¬ ì™„ë£Œ. í˜„ì¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {process.memory_info().rss / 1024 ** 2:.2f} MB\")\n",
        "\n",
        "# ì„¸ì…˜ ìœ ì§€ ì•Œë¦¼ (8ì‹œê°„ë§ˆë‹¤)\n",
        "from IPython.display import display, Javascript\n",
        "display(Javascript('''\n",
        "function alertUser() {\n",
        "  alert(\"ì„¸ì…˜ì„ ìœ ì§€í•˜ê¸° ìœ„í•´ í˜ì´ì§€ì™€ ìƒí˜¸ì‘ìš©í•˜ì„¸ìš”!\");\n",
        "  setTimeout(alertUser, 28800000); // 8ì‹œê°„ë§ˆë‹¤\n",
        "}\n",
        "setTimeout(alertUser, 28800000);\n",
        "'''))\n",
        "\n",
        "# @markdown ## 4. ë°ì´í„°ì…‹ ë¡œë“œ ë° ì¤€ë¹„\n",
        "# ì „ì²˜ë¦¬ëœ ë°ì´í„°ì…‹ì´ ìˆëŠ”ì§€ í™•ì¸\n",
        "train_processed_path = os.path.join(preprocessed_dir, \"train_dataset\")\n",
        "eval_processed_path = os.path.join(preprocessed_dir, \"eval_dataset\")\n",
        "\n",
        "use_preprocessed = os.path.exists(train_processed_path) and os.path.exists(eval_processed_path)\n",
        "\n",
        "if use_preprocessed:\n",
        "    logger.info(\"ì „ì²˜ë¦¬ëœ ë°ì´í„°ì…‹ì„ ë¡œë“œí•©ë‹ˆë‹¤...\")\n",
        "    train_dataset = load_from_disk(train_processed_path)\n",
        "    eval_dataset = load_from_disk(eval_processed_path)\n",
        "    logger.info(f\"ì „ì²˜ë¦¬ëœ ë°ì´í„°ì…‹ ë¡œë“œ ì™„ë£Œ: í›ˆë ¨ {len(train_dataset)}ê°œ, ê²€ì¦ {len(eval_dataset)}ê°œ\")\n",
        "else:\n",
        "    # ë©”íƒ€ë°ì´í„° ë¡œë“œ\n",
        "    metadata_file = os.path.join(dataset_path, \"filtered_data_B.csv\")\n",
        "    try:\n",
        "        df = pd.read_csv(metadata_file)\n",
        "        logger.info(f\"ë©”íƒ€ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(df)}ê°œ í•­ëª©\")\n",
        "\n",
        "        # ë°ì´í„°ì…‹ í¬ê¸° ì œí•œ (ë¬´ë£Œ Colabì—ì„œ ì‹œê°„ ì œí•œ ë‚´ ì™„ë£Œë¥¼ ìœ„í•´)\n",
        "        max_samples = 5000  # @param {type:\"integer\"}\n",
        "        if max_samples and len(df) > max_samples:\n",
        "            df = df.sample(max_samples, random_state=42)\n",
        "            logger.info(f\"ë°ì´í„°ì…‹ í¬ê¸° ì œí•œ: {max_samples}ê°œ ìƒ˜í”Œë§Œ ì‚¬ìš©\")\n",
        "\n",
        "        # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸\n",
        "        required_columns = ['fileName', 'ReadingLabelText']\n",
        "        missing_columns = [col for col in required_columns if col not in df.columns]\n",
        "\n",
        "        if missing_columns:\n",
        "            # ì»¬ëŸ¼ëª… ìë™ ë§¤í•‘ ì‹œë„\n",
        "            if 'fileName' in missing_columns and 'file_name' in df.columns:\n",
        "                df['fileName'] = df['file_name']\n",
        "                missing_columns.remove('fileName')\n",
        "\n",
        "            if 'ReadingLabelText' in missing_columns:\n",
        "                # ê°€ëŠ¥í•œ ëŒ€ì²´ ì»¬ëŸ¼ëª…ë“¤\n",
        "                text_column_candidates = ['text', 'transcript', 'ReadingLabelText']\n",
        "                for col in text_column_candidates:\n",
        "                    if col in df.columns:\n",
        "                        df['ReadingLabelText'] = df[col]\n",
        "                        missing_columns.remove('ReadingLabelText')\n",
        "                        break\n",
        "\n",
        "        if missing_columns:\n",
        "            raise ValueError(f\"CSV íŒŒì¼ì— í•„ìˆ˜ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤: {missing_columns}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"ë©”íƒ€ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
        "        raise\n",
        "\n",
        "    # ë°ì´í„°ì…‹ ë¶„í•  (í›ˆë ¨:ê²€ì¦ = 95:5)\n",
        "    from sklearn.model_selection import train_test_split\n",
        "\n",
        "    train_df, eval_df = train_test_split(df, test_size=0.05, random_state=42)\n",
        "    logger.info(f\"í›ˆë ¨ ë°ì´í„°: {len(train_df)}ê°œ, ê²€ì¦ ë°ì´í„°: {len(eval_df)}ê°œ\")\n",
        "\n",
        "    # ë©”ëª¨ë¦¬ ì •ë¦¬\n",
        "    del df\n",
        "    clear_memory()\n",
        "\n",
        "    # ë°ì´í„°ì…‹ ìƒì„± í•¨ìˆ˜\n",
        "    def create_dataset(dataframe, audio_dir, desc=\"ë°ì´í„°ì…‹ ìƒì„±\"):\n",
        "        # ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ ìƒì„± ë° ì¡´ì¬ í™•ì¸\n",
        "        audio_paths = []\n",
        "        texts = []\n",
        "\n",
        "        for idx, row in tqdm(dataframe.iterrows(), total=len(dataframe), desc=desc):\n",
        "            # íŒŒì¼ëª…ì— í™•ì¥ìê°€ ì—†ìœ¼ë©´ ì¶”ê°€\n",
        "            filename = row['fileName']\n",
        "            if not filename.lower().endswith('.wav'):\n",
        "                filename += '.wav'\n",
        "\n",
        "            file_path = os.path.join(audio_dir, filename)\n",
        "\n",
        "            # íŒŒì¼ ì¡´ì¬ í™•ì¸\n",
        "            if os.path.exists(file_path):\n",
        "                audio_paths.append(file_path)\n",
        "                texts.append(row['ReadingLabelText'])\n",
        "            else:\n",
        "                logger.warning(f\"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}\")\n",
        "\n",
        "        if not audio_paths:\n",
        "            raise ValueError(f\"ìœ íš¨í•œ ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”: {audio_dir}\")\n",
        "\n",
        "        # ë°ì´í„°ì…‹ ì‚¬ì „ ìƒì„±\n",
        "        dataset_dict = {\n",
        "            \"audio\": audio_paths,\n",
        "            \"text\": texts\n",
        "        }\n",
        "\n",
        "        # ë°ì´í„°ì…‹ ìƒì„±\n",
        "        dataset = Dataset.from_dict(dataset_dict)\n",
        "        dataset = dataset.cast_column(\"audio\", Audio(sampling_rate=16000))\n",
        "        return dataset\n",
        "\n",
        "    # í›ˆë ¨ ë° ê²€ì¦ ë°ì´í„°ì…‹ ìƒì„±\n",
        "    audio_dir = dataset_path\n",
        "    if not os.path.exists(os.path.join(audio_dir, train_df['fileName'].iloc[0])):\n",
        "        # í™•ì¥ì í™•ì¸\n",
        "        if not train_df['fileName'].iloc[0].lower().endswith('.wav'):\n",
        "            logger.info(\"íŒŒì¼ëª…ì— .wav í™•ì¥ì ì¶”ê°€ í•„ìš”\")\n",
        "    else:\n",
        "        logger.info(f\"ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ í™•ì¸ ì™„ë£Œ: {audio_dir}\")\n",
        "\n",
        "    try:\n",
        "        train_dataset = create_dataset(train_df, audio_dir, \"í›ˆë ¨ ë°ì´í„°ì…‹ ìƒì„±\")\n",
        "        # ë©”ëª¨ë¦¬ ì •ë¦¬\n",
        "        del train_df\n",
        "        clear_memory()\n",
        "\n",
        "        eval_dataset = create_dataset(eval_df, audio_dir, \"ê²€ì¦ ë°ì´í„°ì…‹ ìƒì„±\")\n",
        "        # ë©”ëª¨ë¦¬ ì •ë¦¬\n",
        "        del eval_df\n",
        "        clear_memory()\n",
        "\n",
        "        # ë°ì´í„°ì…‹ í™•ì¸\n",
        "        logger.info(f\"í›ˆë ¨ ë°ì´í„°ì…‹: {len(train_dataset)}ê°œ\")\n",
        "        logger.info(f\"ê²€ì¦ ë°ì´í„°ì…‹: {len(eval_dataset)}ê°œ\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"ë°ì´í„°ì…‹ ìƒì„± ì‹¤íŒ¨: {e}\")\n",
        "        raise\n",
        "\n",
        "    # @markdown ## 5. ëª¨ë¸ & í”„ë¡œì„¸ì„œ ì„¤ì •\n",
        "    model_name = \"openai/whisper-small\"  # @param [\"openai/whisper-tiny\", \"openai/whisper-base\", \"openai/whisper-small\"]\n",
        "\n",
        "    # í”„ë¡œì„¸ì„œ ë¡œë“œ\n",
        "    try:\n",
        "        processor = WhisperProcessor.from_pretrained(\n",
        "            model_name,\n",
        "            language=\"korean\",  # í•œêµ­ì–´ ì„¤ì •\n",
        "            task=\"transcribe\"\n",
        "        )\n",
        "        logger.info(f\"í”„ë¡œì„¸ì„œ ë¡œë“œ ì™„ë£Œ: {model_name}\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"í”„ë¡œì„¸ì„œ ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
        "        raise\n",
        "\n",
        "    # @markdown ## 6. ë°ì´í„° ì „ì²˜ë¦¬\n",
        "    def prepare_dataset(batch):\n",
        "        try:\n",
        "            # ì˜¤ë””ì˜¤ íŠ¹ì§• ì¶”ì¶œ\n",
        "            audio = batch[\"audio\"]\n",
        "            # float16ìœ¼ë¡œ ì €ì¥í•˜ì—¬ ë©”ëª¨ë¦¬ ì ˆì•½\n",
        "            batch[\"input_features\"] = processor.feature_extractor(\n",
        "                audio[\"array\"],\n",
        "                sampling_rate=audio[\"sampling_rate\"]\n",
        "            ).input_features[0].astype(np.float16)  # float32 ëŒ€ì‹  float16 ì‚¬ìš©\n",
        "\n",
        "            # í…ìŠ¤íŠ¸ í† í°í™”\n",
        "            batch[\"labels\"] = processor.tokenizer(batch[\"text\"]).input_ids\n",
        "            return batch\n",
        "        except Exception as e:\n",
        "            logger.error(f\"ë°ì´í„° ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}\")\n",
        "            # ì˜¤ë¥˜ê°€ ë°œìƒí•´ë„ ê³„ì† ì§„í–‰í•  ìˆ˜ ìˆë„ë¡ ê¸°ë³¸ê°’ ë°˜í™˜\n",
        "            return {\n",
        "                \"input_features\": np.zeros((80, 3000), dtype=np.float16),  # float16 ì‚¬ìš©\n",
        "                \"labels\": [0]\n",
        "            }\n",
        "\n",
        "    # ë°ì´í„°ì…‹ ì „ì²˜ë¦¬ (ë°°ì¹˜ ì²˜ë¦¬ë¡œ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± í–¥ìƒ)\n",
        "    logger.info(\"í›ˆë ¨ ë°ì´í„°ì…‹ ì „ì²˜ë¦¬ ì¤‘...\")\n",
        "    train_dataset = train_dataset.map(\n",
        "        prepare_dataset,\n",
        "        remove_columns=[\"audio\", \"text\"],\n",
        "        batched=False,\n",
        "        desc=\"í›ˆë ¨ ë°ì´í„° ì „ì²˜ë¦¬\",\n",
        "        num_proc=1  # ë‹¨ì¼ í”„ë¡œì„¸ìŠ¤ë¡œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê°ì†Œ\n",
        "    )\n",
        "    # ë©”ëª¨ë¦¬ ì •ë¦¬\n",
        "    clear_memory()\n",
        "\n",
        "    logger.info(\"ê²€ì¦ ë°ì´í„°ì…‹ ì „ì²˜ë¦¬ ì¤‘...\")\n",
        "    eval_dataset = eval_dataset.map(\n",
        "        prepare_dataset,\n",
        "        remove_columns=[\"audio\", \"text\"],\n",
        "        batched=False,\n",
        "        desc=\"ê²€ì¦ ë°ì´í„° ì „ì²˜ë¦¬\",\n",
        "        num_proc=1  # ë‹¨ì¼ í”„ë¡œì„¸ìŠ¤ë¡œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê°ì†Œ\n",
        "    )\n",
        "    # ë©”ëª¨ë¦¬ ì •ë¦¬\n",
        "    clear_memory()\n",
        "\n",
        "    # ì „ì²˜ë¦¬ëœ ë°ì´í„°ì…‹ ì €ì¥\n",
        "    logger.info(\"ì „ì²˜ë¦¬ëœ ë°ì´í„°ì…‹ ì €ì¥ ì¤‘...\")\n",
        "    train_dataset.save_to_disk(train_processed_path)\n",
        "    eval_dataset.save_to_disk(eval_processed_path)\n",
        "    logger.info(f\"ì „ì²˜ë¦¬ëœ ë°ì´í„°ì…‹ ì €ì¥ ì™„ë£Œ: {preprocessed_dir}\")\n",
        "\n",
        "# @markdown ## 5. ëª¨ë¸ & í”„ë¡œì„¸ì„œ ì„¤ì • (ì „ì²˜ë¦¬ëœ ë°ì´í„°ì…‹ ì‚¬ìš© ì‹œì—ë„ í•„ìš”)\n",
        "model_name = \"openai/whisper-small\"  # @param [\"openai/whisper-tiny\", \"openai/whisper-base\", \"openai/whisper-small\"]\n",
        "\n",
        "# í”„ë¡œì„¸ì„œ ë¡œë“œ\n",
        "try:\n",
        "    processor = WhisperProcessor.from_pretrained(\n",
        "        model_name,\n",
        "        language=\"korean\",  # í•œêµ­ì–´ ì„¤ì •\n",
        "        task=\"transcribe\"\n",
        "    )\n",
        "    logger.info(f\"í”„ë¡œì„¸ì„œ ë¡œë“œ ì™„ë£Œ: {model_name}\")\n",
        "except Exception as e:\n",
        "    logger.error(f\"í”„ë¡œì„¸ì„œ ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
        "    raise\n",
        "\n",
        "# ëª¨ë¸ ë¡œë“œ (ì–‘ìí™” ì—†ì´)\n",
        "try:\n",
        "    model = WhisperForConditionalGeneration.from_pretrained(\n",
        "        model_name,\n",
        "        device_map=\"auto\",  # ì–‘ìí™” ì—†ì´ ë¡œë“œ\n",
        "        torch_dtype=torch.float16  # float16 ì •ë°€ë„ ì‚¬ìš©\n",
        "    )\n",
        "    logger.info(f\"ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {model_name}\")\n",
        "except Exception as e:\n",
        "    logger.error(f\"ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
        "    raise\n",
        "\n",
        "# LoRA ì„¤ì •\n",
        "lora_config = LoraConfig(\n",
        "    r=16,\n",
        "    lora_alpha=32,\n",
        "    target_modules=[\"q_proj\", \"v_proj\"],\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\"\n",
        ")\n",
        "\n",
        "# ëª¨ë¸ ì¤€ë¹„\n",
        "try:\n",
        "    model = get_peft_model(model, lora_config)\n",
        "    model.print_trainable_parameters()\n",
        "except Exception as e:\n",
        "    logger.error(f\"LoRA ì„¤ì • ì‹¤íŒ¨: {e}\")\n",
        "    raise\n",
        "\n",
        "# ë©”ëª¨ë¦¬ ì •ë¦¬\n",
        "clear_memory()\n",
        "\n",
        "# @markdown ## 7. í›ˆë ¨ ì„¤ì •\n",
        "# ë©”ëª¨ë¦¬ ìµœì í™”ë¥¼ ìœ„í•œ ë°°ì¹˜ ì„¤ì •\n",
        "batch_size = 2  # @param {type:\"integer\"}\n",
        "gradient_accumulation_steps = 16  # @param {type:\"integer\"}\n",
        "max_steps = 2000  # @param {type:\"integer\"}\n",
        "\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
        "    learning_rate=1e-5,\n",
        "    warmup_ratio=0.1,\n",
        "    max_steps=max_steps,  # ì„¸ì…˜ ì œí•œ ë‚´ ì™„ë£Œë¥¼ ìœ„í•´ ì¡°ì •\n",
        "    fp16=True,\n",
        "    eval_strategy=\"steps\",  # 'evaluation_strategy' ëŒ€ì‹  'eval_strategy' ì‚¬ìš©\n",
        "    eval_steps=500,\n",
        "    save_steps=500,\n",
        "    logging_steps=100,\n",
        "    save_total_limit=2,  # ìµœê·¼ 2ê°œ ì²´í¬í¬ì¸íŠ¸ë§Œ ì €ì¥\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"cer\",\n",
        "    greater_is_better=False,\n",
        "    predict_with_generate=True,\n",
        "    generation_max_length=225,\n",
        "    push_to_hub=False,\n",
        "    report_to=[\"tensorboard\"],\n",
        "    dataloader_num_workers=1,  # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê°ì†Œë¥¼ ìœ„í•´ 1ë¡œ ì„¤ì •\n",
        "    dataloader_pin_memory=True,  # ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± í–¥ìƒ\n",
        ")\n",
        "\n",
        "# @markdown ## 8. í‰ê°€ ë©”íŠ¸ë¦­\n",
        "cer_metric = evaluate.load(\"cer\")\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    try:\n",
        "        pred_ids = pred.predictions\n",
        "        label_ids = pred.label_ids\n",
        "\n",
        "        # íŠ¹ìˆ˜ í† í° ì²˜ë¦¬\n",
        "        label_ids[label_ids == -100] = processor.tokenizer.pad_token_id\n",
        "\n",
        "        # ë””ì½”ë”©\n",
        "        pred_str = processor.batch_decode(pred_ids, skip_special_tokens=True)\n",
        "        label_str = processor.batch_decode(label_ids, skip_special_tokens=True)\n",
        "\n",
        "        # CER ê³„ì‚°\n",
        "        cer = cer_metric.compute(predictions=pred_str, references=label_str)\n",
        "        return {\"cer\": cer}\n",
        "    except Exception as e:\n",
        "        logger.error(f\"ë©”íŠ¸ë¦­ ê³„ì‚° ì‹¤íŒ¨: {e}\")\n",
        "        return {\"cer\": 1.0}  # ì˜¤ë¥˜ ì‹œ ìµœì•…ì˜ ì ìˆ˜ ë°˜í™˜\n",
        "\n",
        "# @markdown ## 9. íŠ¸ë ˆì´ë„ˆ ì„¤ì •\n",
        "# Whisper ëª¨ë¸ìš© ë°ì´í„° ì½œë ˆì´í„°\n",
        "from dataclasses import dataclass\n",
        "from typing import Dict, List, Union, Any\n",
        "import torch\n",
        "\n",
        "@dataclass\n",
        "class DataCollatorSpeechSeq2SeqWithPadding:\n",
        "    processor: Any\n",
        "\n",
        "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
        "        # ì…ë ¥ íŠ¹ì„± ì²˜ë¦¬\n",
        "        input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n",
        "        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n",
        "\n",
        "        # ë ˆì´ë¸” ì²˜ë¦¬\n",
        "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
        "        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n",
        "\n",
        "        # -100ìœ¼ë¡œ íŒ¨ë”©ëœ ë ˆì´ë¸” ëŒ€ì²´ (ì†ì‹¤ ê³„ì‚°ì—ì„œ ë¬´ì‹œë¨)\n",
        "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch[\"input_ids\"] == self.processor.tokenizer.pad_token_id, -100)\n",
        "\n",
        "        batch[\"labels\"] = labels\n",
        "        return batch\n",
        "\n",
        "# ìƒˆ ë°ì´í„° ì½œë ˆì´í„° ì‚¬ìš©\n",
        "data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        "    tokenizer=processor.tokenizer,\n",
        ")\n",
        "\n",
        "# @markdown ## 10. í›ˆë ¨ ì‹¤í–‰ (ì²´í¬í¬ì¸íŠ¸ ë³µêµ¬ ì§€ì›)\n",
        "import glob\n",
        "\n",
        "def find_latest_checkpoint(output_dir):\n",
        "    \"\"\"ê°€ì¥ ìµœê·¼ ì²´í¬í¬ì¸íŠ¸ í´ë” ì°¾ê¸°\"\"\"\n",
        "    checkpoints = glob.glob(os.path.join(output_dir, \"checkpoint-*\"))\n",
        "    if not checkpoints:\n",
        "        return None\n",
        "\n",
        "    # ì²´í¬í¬ì¸íŠ¸ ë²ˆí˜¸ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬\n",
        "    checkpoints = sorted(checkpoints, key=lambda x: int(x.split(\"-\")[-1]))\n",
        "    return checkpoints[-1]  # ê°€ì¥ í° ìˆ«ì(ìµœì‹ ) ì²´í¬í¬ì¸íŠ¸ ë°˜í™˜\n",
        "\n",
        "# ì²´í¬í¬ì¸íŠ¸ í™•ì¸\n",
        "latest_checkpoint = find_latest_checkpoint(output_dir)\n",
        "\n",
        "if latest_checkpoint:\n",
        "    logger.info(f\"ìµœì‹  ì²´í¬í¬ì¸íŠ¸ ë°œê²¬: {latest_checkpoint}\")\n",
        "    try:\n",
        "        trainer.train(resume_from_checkpoint=latest_checkpoint)\n",
        "        logger.info(f\"ì²´í¬í¬ì¸íŠ¸ {os.path.basename(latest_checkpoint)}ì—ì„œ í›ˆë ¨ ì¬ê°œ ì„±ê³µ\")\n",
        "    except Exception as e:\n",
        "        logger.warning(f\"ì²´í¬í¬ì¸íŠ¸ì—ì„œ ì¬ê°œ ì‹¤íŒ¨: {e}\")\n",
        "        logger.info(\"ì²˜ìŒë¶€í„° í›ˆë ¨ì„ ì‹œì‘í•©ë‹ˆë‹¤.\")\n",
        "        trainer.train()\n",
        "else:\n",
        "    logger.info(\"ì²´í¬í¬ì¸íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤. ì²˜ìŒë¶€í„° í›ˆë ¨ì„ ì‹œì‘í•©ë‹ˆë‹¤.\")\n",
        "    trainer.train()\n",
        "\n",
        "# @markdown ## 11. ìµœì¢… ëª¨ë¸ ì €ì¥\n",
        "final_model_path = os.path.join(output_dir, \"final_model\")\n",
        "\n",
        "# LoRA ì–´ëŒ‘í„° ë³‘í•© (ì„ íƒì‚¬í•­)\n",
        "merge_lora = True  # @param {type:\"boolean\"}\n",
        "\n",
        "try:\n",
        "    if merge_lora:\n",
        "        # LoRA ì–´ëŒ‘í„°ë¥¼ ì›ë³¸ ëª¨ë¸ê³¼ ë³‘í•©\n",
        "        # ë¨¼ì € í˜„ì¬ ëª¨ë¸ ì €ì¥\n",
        "        adapter_path = os.path.join(output_dir, \"lora_adapter\")\n",
        "        model.save_pretrained(adapter_path)\n",
        "\n",
        "        # ë©”ëª¨ë¦¬ ì •ë¦¬\n",
        "        del model\n",
        "        clear_memory()\n",
        "\n",
        "        # ì›ë³¸ ëª¨ë¸ ë¡œë“œ\n",
        "        logger.info(\"ì›ë³¸ ëª¨ë¸ ë¡œë“œ ì¤‘...\")\n",
        "        from peft import PeftModel\n",
        "        base_model = WhisperForConditionalGeneration.from_pretrained(\n",
        "            model_name,\n",
        "            device_map=\"auto\",\n",
        "            torch_dtype=torch.float16  # float16 ì •ë°€ë„ ì‚¬ìš©\n",
        "        )\n",
        "\n",
        "        # LoRA ì–´ëŒ‘í„° ë¡œë“œ ë° ë³‘í•©\n",
        "        logger.info(\"LoRA ì–´ëŒ‘í„° ë³‘í•© ì¤‘...\")\n",
        "        peft_model = PeftModel.from_pretrained(base_model, adapter_path)\n",
        "        merged_model = peft_model.merge_and_unload()  # ì–´ëŒ‘í„° ë³‘í•©\n",
        "\n",
        "        # ë©”ëª¨ë¦¬ ì •ë¦¬\n",
        "        del base_model, peft_model\n",
        "        clear_memory()\n",
        "\n",
        "        # ë³‘í•©ëœ ëª¨ë¸ ì €ì¥\n",
        "        logger.info(f\"ë³‘í•©ëœ ëª¨ë¸ ì €ì¥ ì¤‘: {final_model_path}\")\n",
        "        merged_model.save_pretrained(final_model_path)\n",
        "        processor.save_pretrained(final_model_path)\n",
        "        logger.info(f\"LoRA ì–´ëŒ‘í„°ê°€ ë³‘í•©ëœ ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {final_model_path}\")\n",
        "\n",
        "        # ë©”ëª¨ë¦¬ ì •ë¦¬\n",
        "        del merged_model\n",
        "        clear_memory()\n",
        "    else:\n",
        "        # LoRA ì–´ëŒ‘í„°ë§Œ ì €ì¥\n",
        "        logger.info(f\"LoRA ì–´ëŒ‘í„° ëª¨ë¸ ì €ì¥ ì¤‘: {final_model_path}\")\n",
        "        model.save_pretrained(final_model_path)\n",
        "        processor.save_pretrained(final_model_path)\n",
        "        logger.info(f\"LoRA ì–´ëŒ‘í„° ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {final_model_path}\")\n",
        "        logger.warning(\"ì£¼ì˜: ì´ ëª¨ë¸ì„ ë¡œë“œí•  ë•ŒëŠ” LoRA ì„¤ì •ì´ í•„ìš”í•©ë‹ˆë‹¤.\")\n",
        "\n",
        "        # ë©”ëª¨ë¦¬ ì •ë¦¬\n",
        "        del model\n",
        "        clear_memory()\n",
        "except Exception as e:\n",
        "    logger.error(f\"ëª¨ë¸ ì €ì¥ ì‹¤íŒ¨: {e}\")\n",
        "    # ìµœì†Œí•œ LoRA ì–´ëŒ‘í„°ë¼ë„ ì €ì¥\n",
        "    emergency_path = os.path.join(output_dir, \"emergency_save\")\n",
        "    os.makedirs(emergency_path, exist_ok=True)\n",
        "    model.save_pretrained(emergency_path)\n",
        "    processor.save_pretrained(emergency_path)\n",
        "    logger.info(f\"ë¹„ìƒ ì €ì¥ ì™„ë£Œ: {emergency_path}\")\n",
        "\n",
        "# @markdown ## 12. ëª¨ë¸ í…ŒìŠ¤íŠ¸ (ì„ íƒì‚¬í•­)\n",
        "test_model = True  # @param {type:\"boolean\"}\n",
        "\n",
        "if test_model:\n",
        "    from transformers import pipeline\n",
        "\n",
        "    # í…ŒìŠ¤íŠ¸í•  ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ\n",
        "    test_audio = \"/content/drive/MyDrive/sample.wav\"  # @param {type:\"string\"}\n",
        "\n",
        "    if not os.path.exists(test_audio):\n",
        "        logger.warning(f\"í…ŒìŠ¤íŠ¸ ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {test_audio}\")\n",
        "    else:\n",
        "        try:\n",
        "            # íŒŒì´í”„ë¼ì¸ ìƒì„±\n",
        "            pipe = pipeline(\n",
        "                \"automatic-speech-recognition\",\n",
        "                model=final_model_path,\n",
        "                chunk_length_s=30,\n",
        "                device=0 if torch.cuda.is_available() else -1,\n",
        "            )\n",
        "\n",
        "            # í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
        "            result = pipe(test_audio, return_timestamps=True)\n",
        "            logger.info(f\"ì¸ì‹ ê²°ê³¼: {result['text']}\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}\")\n",
        "\n",
        "logger.info(\"íŒŒì¸íŠœë‹ í”„ë¡œì„¸ìŠ¤ ì™„ë£Œ!\")\n"
      ]
    }
  ]
}