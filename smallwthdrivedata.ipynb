{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNCxwbLPJqe69mIhkIKxr2F",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KTFplus/KTFfintune/blob/master/smallwthdrivedata.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q torch transformers datasets librosa evaluate jiwer peft soundfile"
      ],
      "metadata": {
        "id": "QGkVEFg5-HGH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xft0bzQr-Db7"
      },
      "outputs": [],
      "source": [
        "# @title Whisper 파인튜닝을 위한 Colab 최적화 코드 (RAM 최적화 버전)\n",
        "# @markdown ## 1. 필수 패키지 설치 (필요한 경우 실행)\n",
        "# !pip install -q transformers datasets librosa evaluate jiwer peft soundfile\n",
        "\n",
        "# @markdown ## 2. Google Drive 마운트\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# @markdown ## 3. 경로 및 기본 설정\n",
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gc\n",
        "import logging\n",
        "from tqdm.auto import tqdm\n",
        "from datasets import Dataset, Audio, load_from_disk\n",
        "from transformers import (\n",
        "    WhisperProcessor,\n",
        "    WhisperForConditionalGeneration,\n",
        "    Seq2SeqTrainer,\n",
        "    Seq2SeqTrainingArguments,\n",
        "    DataCollatorForSeq2Seq\n",
        ")\n",
        "from peft import LoraConfig, get_peft_model\n",
        "import evaluate\n",
        "\n",
        "# PyTorch 메모리 단편화 방지 설정\n",
        "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:128'\n",
        "\n",
        "# 로깅 설정\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# 데이터셋 경로 (Google Drive 내 위치)\n",
        "dataset_path = \"/content/drive/MyDrive/train_B_Normalized\"  # @param {type:\"string\"}\n",
        "output_dir = \"/content/drive/MyDrive/whisper_finetuned\"  # @param {type:\"string\"}\n",
        "preprocessed_dir = \"/content/drive/MyDrive/preprocessed_whisper\"  # @param {type:\"string\"}\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "os.makedirs(preprocessed_dir, exist_ok=True)\n",
        "\n",
        "# 메모리 정리 함수 - 더 철저하게\n",
        "def clear_memory():\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "    import psutil\n",
        "    process = psutil.Process(os.getpid())\n",
        "    logger.info(f\"메모리 정리 완료. 현재 메모리 사용량: {process.memory_info().rss / 1024 ** 2:.2f} MB\")\n",
        "\n",
        "# 세션 유지 알림 (8시간마다)\n",
        "from IPython.display import display, Javascript\n",
        "display(Javascript('''\n",
        "function alertUser() {\n",
        "  alert(\"세션을 유지하기 위해 페이지와 상호작용하세요!\");\n",
        "  setTimeout(alertUser, 28800000); // 8시간마다\n",
        "}\n",
        "setTimeout(alertUser, 28800000);\n",
        "'''))\n",
        "\n",
        "# @markdown ## 4. 데이터셋 로드 및 준비\n",
        "# 전처리된 데이터셋이 있는지 확인\n",
        "train_processed_path = os.path.join(preprocessed_dir, \"train_dataset\")\n",
        "eval_processed_path = os.path.join(preprocessed_dir, \"eval_dataset\")\n",
        "\n",
        "use_preprocessed = os.path.exists(train_processed_path) and os.path.exists(eval_processed_path)\n",
        "\n",
        "if use_preprocessed:\n",
        "    logger.info(\"전처리된 데이터셋을 로드합니다...\")\n",
        "    train_dataset = load_from_disk(train_processed_path)\n",
        "    eval_dataset = load_from_disk(eval_processed_path)\n",
        "    logger.info(f\"전처리된 데이터셋 로드 완료: 훈련 {len(train_dataset)}개, 검증 {len(eval_dataset)}개\")\n",
        "else:\n",
        "    # 메타데이터 로드\n",
        "    metadata_file = os.path.join(dataset_path, \"filtered_data_B.csv\")\n",
        "    try:\n",
        "        df = pd.read_csv(metadata_file)\n",
        "        logger.info(f\"메타데이터 로드 완료: {len(df)}개 항목\")\n",
        "\n",
        "        # 데이터셋 크기 제한 (무료 Colab에서 시간 제한 내 완료를 위해)\n",
        "        max_samples = 5000  # @param {type:\"integer\"}\n",
        "        if max_samples and len(df) > max_samples:\n",
        "            df = df.sample(max_samples, random_state=42)\n",
        "            logger.info(f\"데이터셋 크기 제한: {max_samples}개 샘플만 사용\")\n",
        "\n",
        "        # 필수 컬럼 확인\n",
        "        required_columns = ['fileName', 'ReadingLabelText']\n",
        "        missing_columns = [col for col in required_columns if col not in df.columns]\n",
        "\n",
        "        if missing_columns:\n",
        "            # 컬럼명 자동 매핑 시도\n",
        "            if 'fileName' in missing_columns and 'file_name' in df.columns:\n",
        "                df['fileName'] = df['file_name']\n",
        "                missing_columns.remove('fileName')\n",
        "\n",
        "            if 'ReadingLabelText' in missing_columns:\n",
        "                # 가능한 대체 컬럼명들\n",
        "                text_column_candidates = ['text', 'transcript', 'ReadingLabelText']\n",
        "                for col in text_column_candidates:\n",
        "                    if col in df.columns:\n",
        "                        df['ReadingLabelText'] = df[col]\n",
        "                        missing_columns.remove('ReadingLabelText')\n",
        "                        break\n",
        "\n",
        "        if missing_columns:\n",
        "            raise ValueError(f\"CSV 파일에 필수 컬럼이 없습니다: {missing_columns}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"메타데이터 로드 실패: {e}\")\n",
        "        raise\n",
        "\n",
        "    # 데이터셋 분할 (훈련:검증 = 95:5)\n",
        "    from sklearn.model_selection import train_test_split\n",
        "\n",
        "    train_df, eval_df = train_test_split(df, test_size=0.05, random_state=42)\n",
        "    logger.info(f\"훈련 데이터: {len(train_df)}개, 검증 데이터: {len(eval_df)}개\")\n",
        "\n",
        "    # 메모리 정리\n",
        "    del df\n",
        "    clear_memory()\n",
        "\n",
        "    # 데이터셋 생성 함수\n",
        "    def create_dataset(dataframe, audio_dir, desc=\"데이터셋 생성\"):\n",
        "        # 오디오 파일 경로 생성 및 존재 확인\n",
        "        audio_paths = []\n",
        "        texts = []\n",
        "\n",
        "        for idx, row in tqdm(dataframe.iterrows(), total=len(dataframe), desc=desc):\n",
        "            # 파일명에 확장자가 없으면 추가\n",
        "            filename = row['fileName']\n",
        "            if not filename.lower().endswith('.wav'):\n",
        "                filename += '.wav'\n",
        "\n",
        "            file_path = os.path.join(audio_dir, filename)\n",
        "\n",
        "            # 파일 존재 확인\n",
        "            if os.path.exists(file_path):\n",
        "                audio_paths.append(file_path)\n",
        "                texts.append(row['ReadingLabelText'])\n",
        "            else:\n",
        "                logger.warning(f\"파일을 찾을 수 없습니다: {file_path}\")\n",
        "\n",
        "        if not audio_paths:\n",
        "            raise ValueError(f\"유효한 오디오 파일을 찾을 수 없습니다. 경로를 확인하세요: {audio_dir}\")\n",
        "\n",
        "        # 데이터셋 사전 생성\n",
        "        dataset_dict = {\n",
        "            \"audio\": audio_paths,\n",
        "            \"text\": texts\n",
        "        }\n",
        "\n",
        "        # 데이터셋 생성\n",
        "        dataset = Dataset.from_dict(dataset_dict)\n",
        "        dataset = dataset.cast_column(\"audio\", Audio(sampling_rate=16000))\n",
        "        return dataset\n",
        "\n",
        "    # 훈련 및 검증 데이터셋 생성\n",
        "    audio_dir = dataset_path\n",
        "    if not os.path.exists(os.path.join(audio_dir, train_df['fileName'].iloc[0])):\n",
        "        # 확장자 확인\n",
        "        if not train_df['fileName'].iloc[0].lower().endswith('.wav'):\n",
        "            logger.info(\"파일명에 .wav 확장자 추가 필요\")\n",
        "    else:\n",
        "        logger.info(f\"오디오 파일 경로 확인 완료: {audio_dir}\")\n",
        "\n",
        "    try:\n",
        "        train_dataset = create_dataset(train_df, audio_dir, \"훈련 데이터셋 생성\")\n",
        "        # 메모리 정리\n",
        "        del train_df\n",
        "        clear_memory()\n",
        "\n",
        "        eval_dataset = create_dataset(eval_df, audio_dir, \"검증 데이터셋 생성\")\n",
        "        # 메모리 정리\n",
        "        del eval_df\n",
        "        clear_memory()\n",
        "\n",
        "        # 데이터셋 확인\n",
        "        logger.info(f\"훈련 데이터셋: {len(train_dataset)}개\")\n",
        "        logger.info(f\"검증 데이터셋: {len(eval_dataset)}개\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"데이터셋 생성 실패: {e}\")\n",
        "        raise\n",
        "\n",
        "    # @markdown ## 5. 모델 & 프로세서 설정\n",
        "    model_name = \"openai/whisper-small\"  # @param [\"openai/whisper-tiny\", \"openai/whisper-base\", \"openai/whisper-small\"]\n",
        "\n",
        "    # 프로세서 로드\n",
        "    try:\n",
        "        processor = WhisperProcessor.from_pretrained(\n",
        "            model_name,\n",
        "            language=\"korean\",  # 한국어 설정\n",
        "            task=\"transcribe\"\n",
        "        )\n",
        "        logger.info(f\"프로세서 로드 완료: {model_name}\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"프로세서 로드 실패: {e}\")\n",
        "        raise\n",
        "\n",
        "    # @markdown ## 6. 데이터 전처리\n",
        "    def prepare_dataset(batch):\n",
        "        try:\n",
        "            # 오디오 특징 추출\n",
        "            audio = batch[\"audio\"]\n",
        "            # float16으로 저장하여 메모리 절약\n",
        "            batch[\"input_features\"] = processor.feature_extractor(\n",
        "                audio[\"array\"],\n",
        "                sampling_rate=audio[\"sampling_rate\"]\n",
        "            ).input_features[0].astype(np.float16)  # float32 대신 float16 사용\n",
        "\n",
        "            # 텍스트 토큰화\n",
        "            batch[\"labels\"] = processor.tokenizer(batch[\"text\"]).input_ids\n",
        "            return batch\n",
        "        except Exception as e:\n",
        "            logger.error(f\"데이터 전처리 실패: {e}\")\n",
        "            # 오류가 발생해도 계속 진행할 수 있도록 기본값 반환\n",
        "            return {\n",
        "                \"input_features\": np.zeros((80, 3000), dtype=np.float16),  # float16 사용\n",
        "                \"labels\": [0]\n",
        "            }\n",
        "\n",
        "    # 데이터셋 전처리 (배치 처리로 메모리 효율성 향상)\n",
        "    logger.info(\"훈련 데이터셋 전처리 중...\")\n",
        "    train_dataset = train_dataset.map(\n",
        "        prepare_dataset,\n",
        "        remove_columns=[\"audio\", \"text\"],\n",
        "        batched=False,\n",
        "        desc=\"훈련 데이터 전처리\",\n",
        "        num_proc=1  # 단일 프로세스로 메모리 사용량 감소\n",
        "    )\n",
        "    # 메모리 정리\n",
        "    clear_memory()\n",
        "\n",
        "    logger.info(\"검증 데이터셋 전처리 중...\")\n",
        "    eval_dataset = eval_dataset.map(\n",
        "        prepare_dataset,\n",
        "        remove_columns=[\"audio\", \"text\"],\n",
        "        batched=False,\n",
        "        desc=\"검증 데이터 전처리\",\n",
        "        num_proc=1  # 단일 프로세스로 메모리 사용량 감소\n",
        "    )\n",
        "    # 메모리 정리\n",
        "    clear_memory()\n",
        "\n",
        "    # 전처리된 데이터셋 저장\n",
        "    logger.info(\"전처리된 데이터셋 저장 중...\")\n",
        "    train_dataset.save_to_disk(train_processed_path)\n",
        "    eval_dataset.save_to_disk(eval_processed_path)\n",
        "    logger.info(f\"전처리된 데이터셋 저장 완료: {preprocessed_dir}\")\n",
        "\n",
        "# @markdown ## 5. 모델 & 프로세서 설정 (전처리된 데이터셋 사용 시에도 필요)\n",
        "model_name = \"openai/whisper-small\"  # @param [\"openai/whisper-tiny\", \"openai/whisper-base\", \"openai/whisper-small\"]\n",
        "\n",
        "# 프로세서 로드\n",
        "try:\n",
        "    processor = WhisperProcessor.from_pretrained(\n",
        "        model_name,\n",
        "        language=\"korean\",  # 한국어 설정\n",
        "        task=\"transcribe\"\n",
        "    )\n",
        "    logger.info(f\"프로세서 로드 완료: {model_name}\")\n",
        "except Exception as e:\n",
        "    logger.error(f\"프로세서 로드 실패: {e}\")\n",
        "    raise\n",
        "\n",
        "# 모델 로드 (양자화 없이)\n",
        "try:\n",
        "    model = WhisperForConditionalGeneration.from_pretrained(\n",
        "        model_name,\n",
        "        device_map=\"auto\",  # 양자화 없이 로드\n",
        "        torch_dtype=torch.float16  # float16 정밀도 사용\n",
        "    )\n",
        "    logger.info(f\"모델 로드 완료: {model_name}\")\n",
        "except Exception as e:\n",
        "    logger.error(f\"모델 로드 실패: {e}\")\n",
        "    raise\n",
        "\n",
        "# LoRA 설정\n",
        "lora_config = LoraConfig(\n",
        "    r=16,\n",
        "    lora_alpha=32,\n",
        "    target_modules=[\"q_proj\", \"v_proj\"],\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\"\n",
        ")\n",
        "\n",
        "# 모델 준비\n",
        "try:\n",
        "    model = get_peft_model(model, lora_config)\n",
        "    model.print_trainable_parameters()\n",
        "except Exception as e:\n",
        "    logger.error(f\"LoRA 설정 실패: {e}\")\n",
        "    raise\n",
        "\n",
        "# 메모리 정리\n",
        "clear_memory()\n",
        "\n",
        "# @markdown ## 7. 훈련 설정\n",
        "# 메모리 최적화를 위한 배치 설정\n",
        "batch_size = 2  # @param {type:\"integer\"}\n",
        "gradient_accumulation_steps = 16  # @param {type:\"integer\"}\n",
        "max_steps = 2000  # @param {type:\"integer\"}\n",
        "\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
        "    learning_rate=1e-5,\n",
        "    warmup_ratio=0.1,\n",
        "    max_steps=max_steps,  # 세션 제한 내 완료를 위해 조정\n",
        "    fp16=True,\n",
        "    eval_strategy=\"steps\",  # 'evaluation_strategy' 대신 'eval_strategy' 사용\n",
        "    eval_steps=500,\n",
        "    save_steps=500,\n",
        "    logging_steps=100,\n",
        "    save_total_limit=2,  # 최근 2개 체크포인트만 저장\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"cer\",\n",
        "    greater_is_better=False,\n",
        "    predict_with_generate=True,\n",
        "    generation_max_length=225,\n",
        "    push_to_hub=False,\n",
        "    report_to=[\"tensorboard\"],\n",
        "    dataloader_num_workers=1,  # 메모리 사용량 감소를 위해 1로 설정\n",
        "    dataloader_pin_memory=True,  # 메모리 효율성 향상\n",
        ")\n",
        "\n",
        "# @markdown ## 8. 평가 메트릭\n",
        "cer_metric = evaluate.load(\"cer\")\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    try:\n",
        "        pred_ids = pred.predictions\n",
        "        label_ids = pred.label_ids\n",
        "\n",
        "        # 특수 토큰 처리\n",
        "        label_ids[label_ids == -100] = processor.tokenizer.pad_token_id\n",
        "\n",
        "        # 디코딩\n",
        "        pred_str = processor.batch_decode(pred_ids, skip_special_tokens=True)\n",
        "        label_str = processor.batch_decode(label_ids, skip_special_tokens=True)\n",
        "\n",
        "        # CER 계산\n",
        "        cer = cer_metric.compute(predictions=pred_str, references=label_str)\n",
        "        return {\"cer\": cer}\n",
        "    except Exception as e:\n",
        "        logger.error(f\"메트릭 계산 실패: {e}\")\n",
        "        return {\"cer\": 1.0}  # 오류 시 최악의 점수 반환\n",
        "\n",
        "# @markdown ## 9. 트레이너 설정\n",
        "# Whisper 모델용 데이터 콜레이터\n",
        "from dataclasses import dataclass\n",
        "from typing import Dict, List, Union, Any\n",
        "import torch\n",
        "\n",
        "@dataclass\n",
        "class DataCollatorSpeechSeq2SeqWithPadding:\n",
        "    processor: Any\n",
        "\n",
        "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
        "        # 입력 특성 처리\n",
        "        input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n",
        "        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n",
        "\n",
        "        # 레이블 처리\n",
        "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
        "        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n",
        "\n",
        "        # -100으로 패딩된 레이블 대체 (손실 계산에서 무시됨)\n",
        "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch[\"input_ids\"] == self.processor.tokenizer.pad_token_id, -100)\n",
        "\n",
        "        batch[\"labels\"] = labels\n",
        "        return batch\n",
        "\n",
        "# 새 데이터 콜레이터 사용\n",
        "data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        "    tokenizer=processor.tokenizer,\n",
        ")\n",
        "\n",
        "# @markdown ## 10. 훈련 실행 (체크포인트 복구 지원)\n",
        "import glob\n",
        "\n",
        "def find_latest_checkpoint(output_dir):\n",
        "    \"\"\"가장 최근 체크포인트 폴더 찾기\"\"\"\n",
        "    checkpoints = glob.glob(os.path.join(output_dir, \"checkpoint-*\"))\n",
        "    if not checkpoints:\n",
        "        return None\n",
        "\n",
        "    # 체크포인트 번호 기준으로 정렬\n",
        "    checkpoints = sorted(checkpoints, key=lambda x: int(x.split(\"-\")[-1]))\n",
        "    return checkpoints[-1]  # 가장 큰 숫자(최신) 체크포인트 반환\n",
        "\n",
        "# 체크포인트 확인\n",
        "latest_checkpoint = find_latest_checkpoint(output_dir)\n",
        "\n",
        "if latest_checkpoint:\n",
        "    logger.info(f\"최신 체크포인트 발견: {latest_checkpoint}\")\n",
        "    try:\n",
        "        trainer.train(resume_from_checkpoint=latest_checkpoint)\n",
        "        logger.info(f\"체크포인트 {os.path.basename(latest_checkpoint)}에서 훈련 재개 성공\")\n",
        "    except Exception as e:\n",
        "        logger.warning(f\"체크포인트에서 재개 실패: {e}\")\n",
        "        logger.info(\"처음부터 훈련을 시작합니다.\")\n",
        "        trainer.train()\n",
        "else:\n",
        "    logger.info(\"체크포인트가 없습니다. 처음부터 훈련을 시작합니다.\")\n",
        "    trainer.train()\n",
        "\n",
        "# @markdown ## 11. 최종 모델 저장\n",
        "final_model_path = os.path.join(output_dir, \"final_model\")\n",
        "\n",
        "# LoRA 어댑터 병합 (선택사항)\n",
        "merge_lora = True  # @param {type:\"boolean\"}\n",
        "\n",
        "try:\n",
        "    if merge_lora:\n",
        "        # LoRA 어댑터를 원본 모델과 병합\n",
        "        # 먼저 현재 모델 저장\n",
        "        adapter_path = os.path.join(output_dir, \"lora_adapter\")\n",
        "        model.save_pretrained(adapter_path)\n",
        "\n",
        "        # 메모리 정리\n",
        "        del model\n",
        "        clear_memory()\n",
        "\n",
        "        # 원본 모델 로드\n",
        "        logger.info(\"원본 모델 로드 중...\")\n",
        "        from peft import PeftModel\n",
        "        base_model = WhisperForConditionalGeneration.from_pretrained(\n",
        "            model_name,\n",
        "            device_map=\"auto\",\n",
        "            torch_dtype=torch.float16  # float16 정밀도 사용\n",
        "        )\n",
        "\n",
        "        # LoRA 어댑터 로드 및 병합\n",
        "        logger.info(\"LoRA 어댑터 병합 중...\")\n",
        "        peft_model = PeftModel.from_pretrained(base_model, adapter_path)\n",
        "        merged_model = peft_model.merge_and_unload()  # 어댑터 병합\n",
        "\n",
        "        # 메모리 정리\n",
        "        del base_model, peft_model\n",
        "        clear_memory()\n",
        "\n",
        "        # 병합된 모델 저장\n",
        "        logger.info(f\"병합된 모델 저장 중: {final_model_path}\")\n",
        "        merged_model.save_pretrained(final_model_path)\n",
        "        processor.save_pretrained(final_model_path)\n",
        "        logger.info(f\"LoRA 어댑터가 병합된 모델 저장 완료: {final_model_path}\")\n",
        "\n",
        "        # 메모리 정리\n",
        "        del merged_model\n",
        "        clear_memory()\n",
        "    else:\n",
        "        # LoRA 어댑터만 저장\n",
        "        logger.info(f\"LoRA 어댑터 모델 저장 중: {final_model_path}\")\n",
        "        model.save_pretrained(final_model_path)\n",
        "        processor.save_pretrained(final_model_path)\n",
        "        logger.info(f\"LoRA 어댑터 모델 저장 완료: {final_model_path}\")\n",
        "        logger.warning(\"주의: 이 모델을 로드할 때는 LoRA 설정이 필요합니다.\")\n",
        "\n",
        "        # 메모리 정리\n",
        "        del model\n",
        "        clear_memory()\n",
        "except Exception as e:\n",
        "    logger.error(f\"모델 저장 실패: {e}\")\n",
        "    # 최소한 LoRA 어댑터라도 저장\n",
        "    emergency_path = os.path.join(output_dir, \"emergency_save\")\n",
        "    os.makedirs(emergency_path, exist_ok=True)\n",
        "    model.save_pretrained(emergency_path)\n",
        "    processor.save_pretrained(emergency_path)\n",
        "    logger.info(f\"비상 저장 완료: {emergency_path}\")\n",
        "\n",
        "# @markdown ## 12. 모델 테스트 (선택사항)\n",
        "test_model = True  # @param {type:\"boolean\"}\n",
        "\n",
        "if test_model:\n",
        "    from transformers import pipeline\n",
        "\n",
        "    # 테스트할 오디오 파일 경로\n",
        "    test_audio = \"/content/drive/MyDrive/sample.wav\"  # @param {type:\"string\"}\n",
        "\n",
        "    if not os.path.exists(test_audio):\n",
        "        logger.warning(f\"테스트 오디오 파일을 찾을 수 없습니다: {test_audio}\")\n",
        "    else:\n",
        "        try:\n",
        "            # 파이프라인 생성\n",
        "            pipe = pipeline(\n",
        "                \"automatic-speech-recognition\",\n",
        "                model=final_model_path,\n",
        "                chunk_length_s=30,\n",
        "                device=0 if torch.cuda.is_available() else -1,\n",
        "            )\n",
        "\n",
        "            # 테스트 실행\n",
        "            result = pipe(test_audio, return_timestamps=True)\n",
        "            logger.info(f\"인식 결과: {result['text']}\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"모델 테스트 실패: {e}\")\n",
        "\n",
        "logger.info(\"파인튜닝 프로세스 완료!\")\n"
      ]
    }
  ]
}